

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Bayes (Part II) &#8212; The pLoT: A course</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '7_lab';</script>
    <link rel="shortcut icon" href="_static/favicon.png"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Reading" href="7_reading.html" />
    <link rel="prev" title="Lecture" href="7_lecture.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="evaluation.html">Evaluations &amp; project topics</a></li>
<li class="toctree-l1"><a class="reference internal" href="howto.html">Running code in labs</a></li>
<li class="toctree-l1"><a class="reference internal" href="acknowledgments.html">Acknowledgments</a></li>
<li class="toctree-l1"><a class="reference internal" href="askquestion.html">Ask a question!</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Foundations</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="1_topfile.html">Week 1 - Introduction and Plan</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="1_lecture.html">Lecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="1_reading.html">Reading</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="2_topfile.html">Week 2 - LoT Hypothesis I</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="2_lecture.html">Lecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_lab.html">Lab</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_reading.html">Reading</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="3_topfile.html">Week 3 - LoT Hypothesis II</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="3_lecture.html">Lecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_lab.html">Python refresher: Part II</a></li>

<li class="toctree-l2"><a class="reference internal" href="3_reading.html">Reading</a></li>
<li class="toctree-l2"><a class="reference internal" href="3_supplementaryLecture.html">Supplementary content</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="4_topfile.html">Week 4 - Formal Grammars</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="4_lecture.html">Lecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_lab.html">Lab</a></li>
<li class="toctree-l2"><a class="reference internal" href="4_reading.html">Reading</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="5_topfile.html">Week 5 - Semantics</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="5_lecture.html">Lecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="5_lab.html">Lab</a></li>
<li class="toctree-l2"><a class="reference internal" href="5_reading.html">Reading</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="6_topfile.html">Week 6 - Bayes I</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="6_lecture.html">Lecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="6_lab.html">Lab</a></li>
<li class="toctree-l2"><a class="reference internal" href="6_reading.html">Reading</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="7_topfile.html">Week 7 - Bayes II</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="7_lecture.html">Lecture</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Lab</a></li>
<li class="toctree-l2"><a class="reference internal" href="7_reading.html">Reading</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">The probabilistic LoT</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="8_topfile.html">Week 8 - LOTlib3</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="8_lecture.html">Lecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="8_lab.html">Lab</a></li>
<li class="toctree-l2"><a class="reference internal" href="8_reading.html">Reading</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="9_topfile.html">Week 9 - Categorization</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="9_lecture.html">Lecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="9_lab.html">Lab</a></li>
<li class="toctree-l2"><a class="reference internal" href="9_reading.html">Reading</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="10_topfile.html">Week 10 - Case studies I</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="10_lecture.html">Lecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="10_lab.html">Lab</a></li>
<li class="toctree-l2"><a class="reference internal" href="10_reading.html">Reading</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="11_topfile.html">Week 11 - Case studies II</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="11_lecture.html">Lecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="11_lab.html">Lab</a></li>
<li class="toctree-l2"><a class="reference internal" href="11_lab_solved.html">Lab (Solved)</a></li>
<li class="toctree-l2"><a class="reference internal" href="11_reading.html">Reading</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="12_topfile.html">Week 12 - DreamCoder and Conclusions</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="12_lecture.html">Lecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="12_lab.html">Lab</a></li>
<li class="toctree-l2"><a class="reference internal" href="12_lab_solved.html">Lab (Solved)</a></li>
<li class="toctree-l2"><a class="reference internal" href="12_reading.html">Reading</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/thelogicalgrammar/pLoT_course/blob/master/book/7_lab.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/thelogicalgrammar/pLoT_course" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/thelogicalgrammar/pLoT_course/issues/new?title=Issue%20on%20page%20%2F7_lab.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/7_lab.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Bayes (Part II)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-metropolis-hastings-algorithm">The Metropolis-Hastings algorithm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-samples-from-an-unnormalized-normal-distribution">Getting samples from an unnormalized normal distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-mhmc-for-bayesian-inference-categorization-in-continuous-space">Using MHMC for Bayesian inference: categorization in continuous space</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-mhmc-in-discrete-spaces">Using MHMC in discrete spaces</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#homework">Homework</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implemented-mhmc">Implemented MHMC</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="bayes-part-ii">
<h1>Bayes (Part II)<a class="headerlink" href="#bayes-part-ii" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<section id="the-metropolis-hastings-algorithm">
<h2>The Metropolis-Hastings algorithm<a class="headerlink" href="#the-metropolis-hastings-algorithm" title="Permalink to this headline">#</a></h2>
<p>In the lecture this week, we have seen the <em>Metropolis-Hastings</em> algorithm, which allows us to get samples from an <em>unnormalized</em> distribution function, i.e., a function that returns a probability multiplied by some constant factor. Note that this can be any distribution (although in practice we will need it to get samples from an unnormalized posterior).</p>
<p>First of all, have a look at the description of the algorithm and try to implement it as described here.</p>
<blockquote>
<div><p><strong><strong>NOTE</strong></strong> You can find the implemented algo at the bottom of this notebook, but please try by yourself before looking at it!</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mcmc</span><span class="p">(</span><span class="n">nsamples</span><span class="p">,</span> <span class="n">unnorm_prob_f</span><span class="p">,</span> <span class="n">proposalf</span><span class="p">,</span> <span class="n">burnin</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">initial</span><span class="o">=</span><span class="mf">0.</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    nsamples: int</span>
<span class="sd">        Number of samples to draw (includes burnin)</span>
<span class="sd">    unnorm_prob_f: func</span>
<span class="sd">        Function taking a point in the support and</span>
<span class="sd">        returning its unnormalized probability</span>
<span class="sd">    proposalf: func</span>
<span class="sd">        Function that takes current position</span>
<span class="sd">        and returns a proposal for where to move next</span>
<span class="sd">    burnin: int</span>
<span class="sd">        Number of initial samples to exclude</span>
<span class="sd">    initial: float or func</span>
<span class="sd">        If float, starts from that point.</span>
<span class="sd">        If func, starts from the output of initial()</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list</span>
<span class="sd">        A list of samples</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># set initial point in variable &#39;current&#39; and </span>
    <span class="c1"># calculate current probability (&#39;curr_prob&#39;)</span>
    <span class="c1"># ADD CODE HERE</span>
    
    <span class="c1"># we put the samples in list &#39;states&#39;</span>
    <span class="n">states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nsamples</span><span class="p">):</span>
        
        <span class="c1"># append current position to states</span>
        <span class="c1"># ADD CODE HERE</span>
        
        <span class="c1"># proposes a new point</span>
        <span class="c1"># ADD CODE HERE</span>
        
        <span class="c1"># calculate unnormalized probability </span>
        <span class="c1"># at proposed point</span>
        <span class="c1"># ADD CODE HERE</span>
        
        <span class="c1"># calculates probability of acceptance </span>
        <span class="c1"># in variable &#39;acceptance&#39;</span>
        <span class="c1"># ADD CODE HERE</span>
        
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_sample</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">acceptance</span><span class="p">:</span>
            <span class="c1"># if acceptance is higher than random btw 0 and 1,</span>
            <span class="c1"># accept move, else stay where you are (i.e. do nothing)</span>
            <span class="c1"># ADD CODE HERE</span>
    
    <span class="c1"># return list of samples</span>
    <span class="k">return</span> <span class="n">states</span><span class="p">[</span><span class="n">burnin</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<p>This algorithm has a lot of pros:</p>
<ul class="simple">
<li><p>Suprisingly simple to implement</p></li>
<li><p>If we get enough samples it is guaranteed to converge to the true posterior!</p></li>
<li><p>Works for both continuous and discrete parameter spaces
But it also has some cons:</p></li>
<li><p>Can be very slow to converge</p></li>
<li><p>Does not work well with highly dimensional spaces</p></li>
<li><p>There is no way to tell if it converged to the true posterior</p></li>
</ul>
<p>In general, we should get as many samples as possible and run multiple chains with different initial points, to see if they converged to the same distribution.</p>
</section>
<section id="getting-samples-from-an-unnormalized-normal-distribution">
<h2>Getting samples from an unnormalized normal distribution<a class="headerlink" href="#getting-samples-from-an-unnormalized-normal-distribution" title="Permalink to this headline">#</a></h2>
<p>The simplest application is to get samples from a distribution that we can calculate exactly, and see if the algorithm converges to it. Let’s take the standard normal distribution, which has density function:</p>
<p>$$
\varphi (z)= \frac {1}{\sqrt {2\pi }} e^{-{\frac {z^{2}}{2}}}
$$</p>
<p>let’s write a function to calculate this probability density:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">normal</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">mu</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">sigma</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Probability density of normal distribution at x</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">numerator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">((</span><span class="o">-</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="n">sigma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">numerator</span><span class="o">/</span><span class="n">denominator</span>
</pre></div>
</div>
</div>
</div>
<p>And let’s test this function to make sure it does what we expect:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">normal</span><span class="p">(</span><span class="n">xs</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;density&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/2d31b291f622408d8688baddf48f2e2d69ff52be08e6e6a5d5cc4beb98fa35e5.png" src="_images/2d31b291f622408d8688baddf48f2e2d69ff52be08e6e6a5d5cc4beb98fa35e5.png" />
</div>
</div>
<p>Now suppose that we didn’t have the explicit formula for the distribution, but rather some black-box function where $\varphi$ is multiplied by an unknown constant $K$:</p>
<p>$$
\varphi’ (z)= K \frac {1}{\sqrt {2\pi }} e^{-{\frac {z^{2}}{2}}}
$$</p>
<blockquote>
<div><p><strong><strong>NOTE</strong></strong>: If $K$ is equal to the normalization constant $\sqrt {2\pi }$, $\varphi’ (z)$ becomes just $e^{-{\frac {z^{2}}{2}}}$. This is essentially the trick we will use to sample from the posterior, where we don’t have the posterior as such, but we can calculate the posterior multiplied by $P(D)$.</p>
</div></blockquote>
<p>Now we can use our mcmc function above to take samples from the distribution:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span> <span class="o">=</span> <span class="n">mcmc</span><span class="p">(</span>
    <span class="c1"># Number of samples</span>
    <span class="mi">100000</span><span class="p">,</span>
    <span class="c1"># Unnormalized density function</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span>
    <span class="c1"># Proposal function from point x</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can plot a histogram of the samples and compare it to the true distribution, and if you wrote the MCMC function correctly, they should look very close:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot a histogram of the samples</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># also plot the true distribution, just to be sure!</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">normal</span><span class="p">(</span><span class="n">xs</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/25b7c187343639d12dc7f84cdea1057b5afcc0d1b17beb32360110789f7536b4.png" src="_images/25b7c187343639d12dc7f84cdea1057b5afcc0d1b17beb32360110789f7536b4.png" />
</div>
</div>
</section>
<section id="using-mhmc-for-bayesian-inference-categorization-in-continuous-space">
<h2>Using MHMC for Bayesian inference: categorization in continuous space<a class="headerlink" href="#using-mhmc-for-bayesian-inference-categorization-in-continuous-space" title="Permalink to this headline">#</a></h2>
<p>Now recall the categorization case that we saw in class: we observe some samples from an unknown category, and we have to form a posterior over the position of the unseen category’s boundaries. The case we have seen in class has discrete boundaries, and therefore we could in theory calculate the posterior directly: consider all the possible hypotheses (categories) $H$, calculate $P(H) P(D \mid H)$, and sum it all to find $P(D)$.</p>
<p>However, now imagine the case where we have a <em>continuous</em> space, and so infinitely many categories. The probability density of sampling a certain observation from a category is still 0 if the observation lies outside the category and $1/|H|$ otherwise, but now the category $H$ can have a float size (e.g., category [-1, 0.5] has size 1.5). Now it becomes difficult to calculate the $P(D)$, because we can’t easily integrate over all categories!</p>
<p>However, if we define some prior over hypotheses (i.e. the categories), we can still easily calculate the numerator of the posterior, namely $P(H) P(D \mid H)$, for specific categories. A simple prior can be defined as follows:</p>
<p>$$
p(H) = \phi(x=l_H, \mu=0, \sigma=10) ; \phi(x=u_H, \mu=0, \sigma=10)
$$</p>
<p>where $\phi$ is the probability density function of a normal distribution, $l_H$ is the lower bound, and $u_H$ is the upper bound.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prior_f</span><span class="p">(</span><span class="n">boundaries</span><span class="p">):</span>
    <span class="n">lb</span><span class="p">,</span> <span class="n">ub</span> <span class="o">=</span> <span class="n">boundaries</span>
    <span class="k">return</span> <span class="n">normal</span><span class="p">(</span><span class="n">lb</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span> <span class="o">*</span> <span class="n">normal</span><span class="p">(</span><span class="n">ub</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Likelihood can be defined as discussed above:</p>
<p>$$
p(D \mid H) = \prod_{d \in D} \left( |H|^{-1} \text{ if } d \in H \text{ else } 0 \right)
$$</p>
<p>where $D$ is a set of observations (points from the unobserved category).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">likelihood_f</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">boundaries</span><span class="p">):</span>
    <span class="n">lb</span><span class="p">,</span> <span class="n">ub</span> <span class="o">=</span> <span class="n">boundaries</span>
    <span class="n">compatible</span> <span class="o">=</span> <span class="nb">all</span><span class="p">([</span><span class="n">lb</span> <span class="o">&lt;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">ub</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">data</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">compatible</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">ub</span><span class="o">-</span><span class="n">lb</span><span class="p">)</span><span class="o">**</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
</div>
<p>With the prior and the likelihood as defined above, we can write a function that given some data returns the unnormalized posterior function (i.e. a function form a category to the unnormalized posterior probability of the category given the data):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">define_unnorm_posterior</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">unnorm_posterior</span><span class="p">(</span><span class="n">boundaries</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">likelihood_f</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">boundaries</span><span class="p">)</span> <span class="o">*</span> 
            <span class="n">prior_f</span><span class="p">(</span><span class="n">boundaries</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">unnorm_posterior</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, we just need a proposal function that takes a current category and proposes a new one. The proposal function here does this by moving the category up or down and stretching it by some amount:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">proposal_f</span><span class="p">(</span><span class="n">current_boundaries</span><span class="p">):</span>
    <span class="c1"># transform boundaries linearly</span>
    <span class="c1"># (i.e., move up and down and stretch)</span>
    <span class="n">shift</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">()</span>
    <span class="c1"># we want the stretch to be always positive</span>
    <span class="c1"># to preserve order of upper and lower bound</span>
    <span class="c1"># (otherwise all samples with wrong order would</span>
    <span class="c1"># have prob 0 in the likelihood function)</span>
    <span class="c1"># Moreover, a stretching by some value x</span>
    <span class="c1"># should be as likely as a contraction by x</span>
    <span class="c1"># To preserve symmetry!</span>
    <span class="n">stretch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">shift</span> <span class="o">+</span> <span class="n">stretch</span><span class="o">*</span><span class="n">current_boundaries</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s check the distribution of the upper and lower bounds of the proposals starting from category [-1,1]:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">proposed</span> <span class="o">=</span> <span class="p">[</span><span class="n">proposal_f</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">)]</span>
<span class="n">lbs</span><span class="p">,</span> <span class="n">ubs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">proposed</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">lbs</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">ubs</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/1e0069a9e3bdef09962362520b95127043c425a9ffd030a3bea1f0b8d0340302.png" src="_images/1e0069a9e3bdef09962362520b95127043c425a9ffd030a3bea1f0b8d0340302.png" />
</div>
</div>
<p>Now we are ready to run approximate Bayesian inference on some data! Let’s define some data first:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">observations</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Take samples from the posterior distribution:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span> <span class="o">=</span> <span class="n">mcmc</span><span class="p">(</span>
    <span class="c1"># Number of samples</span>
    <span class="mi">500000</span><span class="p">,</span>
    <span class="c1"># Unnormalized density function</span>
    <span class="n">define_unnorm_posterior</span><span class="p">(</span><span class="n">observations</span><span class="p">),</span>
    <span class="c1"># Proposal function from point x</span>
    <span class="n">proposal_f</span><span class="p">,</span>
    <span class="n">initial</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_2721/2883728898.py:42: RuntimeWarning: invalid value encountered in double_scalars
  acceptance = min(move_prob/curr_prob,1)
/tmp/ipykernel_2721/2883728898.py:42: RuntimeWarning: divide by zero encountered in double_scalars
  acceptance = min(move_prob/curr_prob,1)
</pre></div>
</div>
</div>
</div>
<p>Let’s plot the posterior distributions of upper and lower bound:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lbs</span><span class="p">,</span> <span class="n">ubs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">lbs</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Lower bound&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">ubs</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Upper bound&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
    <span class="n">observations</span><span class="p">,</span> 
    <span class="p">[</span><span class="mf">1.</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">observations</span><span class="p">),</span>
    <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;observations&#39;</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/7c2e0e868142dec75930c68e0dce12030d3e0063d4290b910c919acbcf1fdd75.png" src="_images/7c2e0e868142dec75930c68e0dce12030d3e0063d4290b910c919acbcf1fdd75.png" />
</div>
</div>
<blockquote>
<div><p><strong>QUESTION</strong> What happens if we add more observations? Do you see the size effect in continuous space?</p>
</div></blockquote>
<blockquote>
<div><p><strong>EXERCISE</strong> (if there is time left at the end) Write a version of this inference model for 2-d space, where categories are squares and observations are points in 2d space.</p>
</div></blockquote>
</section>
<section id="using-mhmc-in-discrete-spaces">
<h2>Using MHMC in discrete spaces<a class="headerlink" href="#using-mhmc-in-discrete-spaces" title="Permalink to this headline">#</a></h2>
<p>We can use Metropolis-Hastings for discrete hypotheses spaces too! The basic idea is the same: we move around the space of hypotheses, calculating the unnormalized posterior for each point, and accepting new moves according to the rule described in the algo. The only complication is that we can’t use the normal distribution centered at the current position as a proposal distribution, but we must come up with something different.</p>
<p>As an example which will be useful in the future, consider the space of sentences generated by a PCFG as the space of hypotheses. For instance, the following PCFG:</p>
<p>$$
S \rightarrow a | b | Sa | Sb
$$</p>
<p>with uniform substitution probabilities (each $1/3$). The space of hypotheses then would be: ‘a’, ‘b’, ‘aa’, ‘ab’, ‘ba’, ‘bb’, and so on.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">complete</span><span class="p">(</span><span class="n">incomplete_sentence</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">incomplete_sentence</span>
    <span class="n">options</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;Sa&#39;</span><span class="p">,</span> <span class="s1">&#39;Sb&#39;</span><span class="p">]</span>
    <span class="k">while</span> <span class="s1">&#39;S&#39;</span> <span class="ow">in</span> <span class="n">result</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">options</span><span class="p">)</span> <span class="o">+</span> <span class="n">result</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="k">return</span> <span class="n">result</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># test function</span>
<span class="n">complete</span><span class="p">(</span><span class="s1">&#39;Saa&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;aaa&#39;
</pre></div>
</div>
</div>
</div>
<p>The probability of a specific sentence of length $n$ then is $4^{-n}$ (can you see why?). Let’s verify by sampling a bunch of sentences and finding the proportion of times we sample each one:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">complete</span><span class="p">(</span><span class="s1">&#39;S&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
<span class="n">sentences</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">argsort</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">counts</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="n">sentences</span><span class="p">[</span><span class="n">argsort</span><span class="p">]</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">counts</span><span class="p">[</span><span class="n">argsort</span><span class="p">]</span> <span class="o">/</span> <span class="n">n</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">sentences</span><span class="p">[:</span><span class="mi">20</span><span class="p">],</span> <span class="n">height</span><span class="o">=</span><span class="n">counts</span><span class="p">[:</span><span class="mi">20</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/65b5576e5e97a7075f63055bc3b621f94640ded764686974b1104a664cafa5f2.png" src="_images/65b5576e5e97a7075f63055bc3b621f94640ded764686974b1104a664cafa5f2.png" />
</div>
</div>
<p>Based on this, it is easy to calculate the probability of each sentence:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prior_f</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">4</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># example of prior calculation</span>
<span class="n">prior_f</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.25
</pre></div>
</div>
</div>
</div>
<p>We want to learn the sentence that produces some data. If we can see the sentence directly, this is easy: just look at the sentence and we’re done. However, suppose that we can’t see the sentence directly, but we see a ‘noisy’ version of it, where possibly some characters have been added at the end, where:</p>
<ul class="simple">
<li><p>nothing is added with probability 1/3.</p></li>
<li><p>‘a’ and ‘b’ are added with probability 1/3 each.</p></li>
</ul>
<p>We can calculate the resulting observation probability:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">likelihood_f</span><span class="p">(</span><span class="n">observations</span><span class="p">,</span> <span class="n">sentence</span><span class="p">):</span>
    <span class="n">likelihood</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">observation</span> <span class="ow">in</span> <span class="n">observations</span><span class="p">:</span>
        <span class="c1"># Calculates probability of observation given true sentence</span>
        <span class="k">if</span> <span class="n">observation</span> <span class="o">==</span> <span class="n">sentence</span><span class="p">:</span>
            <span class="n">likelihood</span> <span class="o">*=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span>
        <span class="k">elif</span> <span class="n">observation</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
            <span class="n">likelihood</span> <span class="o">*=</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span><span class="o">**</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">likelihood</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># test the function</span>
<span class="nb">print</span><span class="p">(</span><span class="n">likelihood_f</span><span class="p">([</span><span class="s1">&#39;abaa&#39;</span><span class="p">,</span> <span class="s1">&#39;abaaa&#39;</span><span class="p">,</span> <span class="s1">&#39;aba&#39;</span><span class="p">],</span> <span class="s1">&#39;ab&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">likelihood_f</span><span class="p">([</span><span class="s1">&#39;abaa&#39;</span><span class="p">,</span> <span class="s1">&#39;abaaa&#39;</span><span class="p">,</span> <span class="s1">&#39;abab&#39;</span><span class="p">],</span> <span class="s1">&#39;ab&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">likelihood_f</span><span class="p">([</span><span class="s1">&#39;abaa&#39;</span><span class="p">,</span> <span class="s1">&#39;abaaa&#39;</span><span class="p">,</span> <span class="s1">&#39;abab&#39;</span><span class="p">],</span> <span class="s1">&#39;abb&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.001371742112482853
0.00045724737082761767
0
</pre></div>
</div>
</div>
</div>
<p>Like in the example above, we can now calculate the unnormalized posterior:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">define_unnorm_posterior</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">unnorm_posterior</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">likelihood_f</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">sentence</span><span class="p">)</span> <span class="o">*</span> 
            <span class="n">prior_f</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">unnorm_posterior</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, we need a proposal distribution, which brings us from a current sentence to a possible next step. For MHMC to work as written above, it has to be the case that the probability of going from $x$ to $x’$ is the same as the probability of going from $x’$ to $x$. If this is not the case, we need to multiply the value of <code class="docutils literal notranslate"><span class="pre">acceptance</span></code> in <code class="docutils literal notranslate"><span class="pre">mcmc</span></code> by $\frac{P(x’ \rightarrow x) }{ P(x \rightarrow x’)}$ to balance things out.</p>
<p>In practice, we will use the <em>subtree-regeneration</em> transition distribution proposed at p.153 in Goodman, Noah D., Joshua B. Tenenbaum, Jacob Feldman, and Thomas L. Griffiths. “A Rational Analysis of Rule-Based Concept Learning.” Cognitive Science 32, no. 1 (2008): 108–54. https://doi.org/10.1080/03640210701802071. It works as follows, starting from current sentence $x$:</p>
<ul class="simple">
<li><p>Sample a node $n$ at random from the parse tree of $x$</p></li>
<li><p>Remove everything below $n$ and replace $n$ with appropriate non-terminal, generating a tree $y$ containing non-terminals.</p></li>
<li><p>Complete $y$ with the PCFG, obtaining new sentence $x’$.</p></li>
<li><p>The acceptance probability from <code class="docutils literal notranslate"><span class="pre">mcmc</span></code> then gets additionally multiplied by:</p></li>
</ul>
<div class="amsmath math notranslate nohighlight" id="equation-2061d596-fb0c-4ecc-8752-57902a72fede">
<span class="eqno">(3)<a class="headerlink" href="#equation-2061d596-fb0c-4ecc-8752-57902a72fede" title="Permalink to this equation">#</a></span>\[\begin{align}
\frac{p(x' \rightarrow x)}{p(x \rightarrow x')} 
&amp;= 
\frac{ P(\text{sampling node $n$ from $x'$}) }{ P(\text{sampling node $n$ from $x'$}) } 
\frac{ P(x \mid \text{PCFG}) }{ P(x' \mid \text{PCFG}) } \\
&amp;= \frac{|x'|^{-1}}{|x|^{-1}} \frac{4^{-|x|}}{4^{-|x'|}} \\
&amp;= \frac{|x|}{|x'|} \frac{4^{-|x|}}{4^{-|x'|}}
\end{align}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transition_f</span><span class="p">(</span><span class="n">current</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">current</span><span class="p">))</span>
    <span class="n">truncated</span> <span class="o">=</span> <span class="s1">&#39;S&#39;</span> <span class="o">+</span> <span class="n">current</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">complete</span><span class="p">(</span><span class="n">truncated</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># test the function</span>
<span class="n">transition_f</span><span class="p">(</span><span class="s1">&#39;aba&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;bbb&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">acceptance_f</span><span class="p">(</span><span class="n">current</span><span class="p">,</span> <span class="n">proposed</span><span class="p">,</span> <span class="n">unnorm_prob_f</span><span class="p">):</span>
    <span class="n">move_when_lower</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="n">unnorm_prob_f</span><span class="p">(</span><span class="n">proposed</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">current</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.25</span><span class="o">**</span><span class="nb">len</span><span class="p">(</span><span class="n">current</span><span class="p">))</span>
        <span class="o">/</span>
        <span class="p">(</span><span class="n">unnorm_prob_f</span><span class="p">(</span><span class="n">current</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">proposed</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.25</span><span class="o">**</span><span class="nb">len</span><span class="p">(</span><span class="n">proposed</span><span class="p">))</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="nb">min</span><span class="p">(</span>
        <span class="n">move_when_lower</span><span class="p">,</span>
        <span class="mi">1</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mcmc</span><span class="p">(</span><span class="n">nsamples</span><span class="p">,</span> <span class="n">unnorm_prob_f</span><span class="p">,</span> <span class="n">proposalf</span><span class="p">,</span> <span class="n">burnin</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">initial</span><span class="o">=</span><span class="mf">0.</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Same as mcmc above but with different acceptance_f</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">current</span> <span class="o">=</span> <span class="n">initial</span><span class="p">()</span> <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">initial</span><span class="p">)</span> <span class="k">else</span> <span class="n">initial</span>
    <span class="n">curr_prob</span> <span class="o">=</span> <span class="n">unnorm_prob_f</span><span class="p">(</span><span class="n">current</span><span class="p">)</span>
    <span class="n">states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nsamples</span><span class="p">):</span>
        <span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current</span><span class="p">)</span>
        <span class="n">movement</span> <span class="o">=</span> <span class="n">proposalf</span><span class="p">(</span><span class="n">current</span><span class="p">)</span>
        <span class="n">move_prob</span> <span class="o">=</span> <span class="n">unnorm_prob_f</span><span class="p">(</span><span class="n">movement</span><span class="p">)</span>
        <span class="n">acceptance</span> <span class="o">=</span> <span class="n">acceptance_f</span><span class="p">(</span>
            <span class="n">current</span><span class="p">,</span> 
            <span class="n">movement</span><span class="p">,</span>
            <span class="n">unnorm_prob_f</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_sample</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">acceptance</span><span class="p">:</span>
            <span class="n">current</span> <span class="o">=</span> <span class="n">movement</span>
            <span class="n">curr_prob</span> <span class="o">=</span> <span class="n">move_prob</span>
    <span class="k">return</span> <span class="n">states</span><span class="p">[</span><span class="n">burnin</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<p>Define some observations:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">observations</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;aabaab&#39;</span><span class="p">,</span> <span class="s1">&#39;aaba&#39;</span><span class="p">,</span> <span class="s1">&#39;aabaaaa&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Take samples with our algorithm:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">samples</span> <span class="o">=</span> <span class="n">mcmc</span><span class="p">(</span>
    <span class="mi">100000</span><span class="p">,</span>
    <span class="n">define_unnorm_posterior</span><span class="p">(</span><span class="n">observations</span><span class="p">),</span>
    <span class="n">transition_f</span><span class="p">,</span>
    <span class="n">initial</span><span class="o">=</span><span class="s1">&#39;a&#39;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Plot the posterior distribution:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sentences</span><span class="p">,</span> <span class="n">counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">argsort</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">counts</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">sentences</span> <span class="o">=</span> <span class="n">sentences</span><span class="p">[</span><span class="n">argsort</span><span class="p">]</span>
<span class="n">counts</span> <span class="o">=</span> <span class="n">counts</span><span class="p">[</span><span class="n">argsort</span><span class="p">]</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">sentences</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">counts</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/265a7256ed325f53a0df8f5b3c5f2dd92d950b0eeaf1093f995a362182636fa2.png" src="_images/265a7256ed325f53a0df8f5b3c5f2dd92d950b0eeaf1093f995a362182636fa2.png" />
</div>
</div>
<p>Various things to be noticed:</p>
<ul class="simple">
<li><p>The most likely sentence is the longest sentence that all the observations share, namely ‘aaba’</p></li>
<li><p>The second most likely is ‘aab’, because it would be a ‘suspicious’ coincidence if all observations independently produced an ‘a’ right after ‘aab’, if the true sentence is indeed ‘aab’.</p></li>
<li><p>Same, but even more so, applies to ‘aa’ and ‘a’.</p></li>
<li><p>So even though ‘aaba’ is a priori less likely than ‘a’, it get a higher posterior probability because of the likelihood!</p></li>
</ul>
</section>
<section id="homework">
<h2>Homework<a class="headerlink" href="#homework" title="Permalink to this headline">#</a></h2>
<p>Third (and last) homeworks set! Consider the following CFG (interpret it as a PCFG with uniform probabilities), where each sentence from this grammar is an integer:
$$
S \rightarrow 1 | S+1 | S-1
$$
Note that there are multiple way to arrive at the same integer. E.g. $I(1+1-1)=I(1)$.</p>
<ol class="arabic simple">
<li><p>Write a function <code class="docutils literal notranslate"><span class="pre">prior_f</span></code> that takes a sentence produced by the PCFG and returns its probability in the PCFG.</p></li>
</ol>
<p>Assume that there is a true (unknown) sentence $H$ that we are trying to infer based on some observations ${o_1, \dots, o_n}$. The observations aren’t just the integer defined by the sentence, but rather each observation is equal to the integer defined by the sentence plus some normally distributed noise. The likelihood function therefore is as follows:
$$
p(o \mid H) = \phi(x= o-I(H), \mu=0, \sigma=2.)
$$
as usual, $I$ is the interpretation function, $\phi$ is the density function of the normal distribution. For instance if the true sentence was <code class="docutils literal notranslate"><span class="pre">1+1</span></code>, we might observe 1.94.</p>
<ol class="arabic simple" start="2">
<li><p>Write a function <code class="docutils literal notranslate"><span class="pre">likelihood_f</span></code> that calculates the probability of a list of observations given a sentence.</p></li>
</ol>
<blockquote>
<div><p><strong>HINT</strong> First find the integer $i$ defined by the sentence, then for each observation find the difference between $i$ and the observation, then find the probability of those differences (given that they are samples from a normal with $\mu=0$ and $\sigma=2$), and multiply those probabilities together.</p>
</div></blockquote>
<ol class="arabic simple" start="3">
<li><p>Write a function to calculate the unnormalized posterior. This is essentially what the <code class="docutils literal notranslate"><span class="pre">define_unnorm_posterior</span></code> function above does.</p></li>
<li><p>Write a transition function: a function that takes a current sentence $x$ and returns a randomly generated proposal $x’$. You can modify the subtree-regeneration above to adapt it to this case.</p></li>
<li><p>Using mcmc, draw 100000 samples from $P(H \mid D)$.</p></li>
</ol>
</section>
<section id="implemented-mhmc">
<h2>Implemented MHMC<a class="headerlink" href="#implemented-mhmc" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mcmc</span><span class="p">(</span><span class="n">nsamples</span><span class="p">,</span> <span class="n">unnorm_prob_f</span><span class="p">,</span> <span class="n">proposalf</span><span class="p">,</span> <span class="n">burnin</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">initial</span><span class="o">=</span><span class="mf">0.</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    nsamples: int</span>
<span class="sd">        Number of samples to draw (includes burnin)</span>
<span class="sd">    unnorm_prob_f: func</span>
<span class="sd">        Function taking a point in the support and</span>
<span class="sd">        returning its unnormalized probability</span>
<span class="sd">    proposalf: func</span>
<span class="sd">        Function that takes current position</span>
<span class="sd">        and returns a proposal for where to move next</span>
<span class="sd">    burnin: int</span>
<span class="sd">        Number of initial samples to exclude</span>
<span class="sd">    initial: float or func</span>
<span class="sd">        If float, starts from that point.</span>
<span class="sd">        If func, starts from the output of initial()</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list</span>
<span class="sd">        A list of samples</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">current</span> <span class="o">=</span> <span class="n">initial</span><span class="p">()</span> <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">initial</span><span class="p">)</span> <span class="k">else</span> <span class="n">initial</span>
    <span class="n">curr_prob</span> <span class="o">=</span> <span class="n">unnorm_prob_f</span><span class="p">(</span><span class="n">current</span><span class="p">)</span>
    
    <span class="c1"># we put the samples in list &#39;states&#39;</span>
    <span class="n">states</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nsamples</span><span class="p">):</span>
        
        <span class="c1"># append current position to states</span>
        <span class="n">states</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current</span><span class="p">)</span>
        
        <span class="c1"># proposes a new point</span>
        <span class="n">movement</span> <span class="o">=</span> <span class="n">proposalf</span><span class="p">(</span><span class="n">current</span><span class="p">)</span>
        
        <span class="c1"># calculate unnormalized probability </span>
        <span class="c1"># at proposed point</span>
        <span class="n">move_prob</span> <span class="o">=</span> <span class="n">unnorm_prob_f</span><span class="p">(</span><span class="n">movement</span><span class="p">)</span>
        
        <span class="c1"># calculates probability of acceptance</span>
        <span class="n">acceptance</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">move_prob</span><span class="o">/</span><span class="n">curr_prob</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        
        <span class="c1"># if acceptance is higher than random btw 0 and 1,</span>
        <span class="c1"># accept move, else stay where you are (i.e. do nothing)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_sample</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">acceptance</span><span class="p">:</span>
            <span class="n">current</span> <span class="o">=</span> <span class="n">movement</span>
            <span class="n">curr_prob</span> <span class="o">=</span> <span class="n">move_prob</span>
    
    <span class="c1"># return list of samples</span>
    <span class="k">return</span> <span class="n">states</span><span class="p">[</span><span class="n">burnin</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "plot"
        },
        kernelOptions: {
            name: "plot",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'plot'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="7_lecture.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Lecture</p>
      </div>
    </a>
    <a class="right-next"
       href="7_reading.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Reading</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-metropolis-hastings-algorithm">The Metropolis-Hastings algorithm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-samples-from-an-unnormalized-normal-distribution">Getting samples from an unnormalized normal distribution</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-mhmc-for-bayesian-inference-categorization-in-continuous-space">Using MHMC for Bayesian inference: categorization in continuous space</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-mhmc-in-discrete-spaces">Using MHMC in discrete spaces</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#homework">Homework</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implemented-mhmc">Implemented MHMC</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Fausto Carcassi
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>