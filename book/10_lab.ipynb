{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08e45eee-6888-4947-be6c-b248ec58598e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Category acquisition in an LoT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17559afa-ed12-45bb-81ff-6b86b6aa4017",
   "metadata": {},
   "source": [
    "> __**NOTE**__ This is based on Piantadosi's example [here](https://github.com/piantado/LOTlib3/blob/master/Examples/RationalRules/Model.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cffd3dc-44e8-41cc-819b-3f0bc6f28f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in colab!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # in colab\n",
    "    import google.colab\n",
    "    print('In colab, downloading LOTlib3')\n",
    "    !git clone https://github.com/thelogicalgrammar/LOTlib3\n",
    "except:\n",
    "    # not in colab\n",
    "    print('Not in colab!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9284ac03-139b-4d49-a216-2deaf4998ddc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf769d5-fa8e-4682-8e22-28ad71b3b514",
   "metadata": {},
   "source": [
    "First we need to import a bunch of stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad9bcf47-102b-432d-ae81-a3522e2fe3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac1342f3-ea28-457b-a0b8-33f065dfd928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LOTlib3.Miscellaneous import q, random\n",
    "from LOTlib3.Grammar import Grammar\n",
    "from LOTlib3.DataAndObjects import FunctionData, Obj\n",
    "from LOTlib3.Hypotheses.LOTHypothesis import LOTHypothesis\n",
    "from LOTlib3.Hypotheses.Priors.RationalRules import RationaRulesPrior\n",
    "from LOTlib3.Hypotheses.Likelihoods.BinaryLikelihood import BinaryLikelihood\n",
    "from LOTlib3.Eval import primitive\n",
    "from LOTlib3.Miscellaneous import qq\n",
    "from LOTlib3.TopN import TopN\n",
    "from LOTlib3.Samplers.MetropolisHastings import MetropolisHastingsSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e1989c-9d4f-4b39-93a2-5d617dd30c0e",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44ec65e-7351-4245-aeb2-c0feb7a559d6",
   "metadata": {},
   "source": [
    "This is a version of the model in the paper we have discussed in class. The learner sees a series of objects and learns a posterior over logical expressions, where each logical expression encodes a category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0722cd87-d539-4713-bf04-cde22f029ff5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243d79da-a6e3-4afd-953b-0dd068b7326f",
   "metadata": {},
   "source": [
    "First, we need a function to generate the data. This is the function that Piantadosi uses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61777799-98b3-4d1d-a1b1-12e947a8913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(n=1, alpha=0.999):\n",
    "    return [\n",
    "        FunctionData(input=[Obj(shape='square', color='red')], output=True, alpha=alpha),\n",
    "        FunctionData(input=[Obj(shape='square', color='blue')], output=False, alpha=alpha),\n",
    "        FunctionData(input=[Obj(shape='triangle', color='blue')], output=False, alpha=alpha),\n",
    "        FunctionData(input=[Obj(shape='triangle', color='red')], output=False, alpha=alpha)\n",
    "    ]*n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3d7fe8-8eab-4708-b7c2-a29543cab872",
   "metadata": {},
   "source": [
    "But we can easily write other functions, e.g., one that randomly selects datapoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc3f0d00-8615-4357-b73f-2d97649240f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(n=1, alpha=0.999):\n",
    "    return np.random.choice(\n",
    "        [\n",
    "            FunctionData(input=[Obj(shape='square', color='red')], output=True, alpha=alpha),\n",
    "            FunctionData(input=[Obj(shape='square', color='blue')], output=False, alpha=alpha),\n",
    "            FunctionData(input=[Obj(shape='triangle', color='blue')], output=False, alpha=alpha),\n",
    "            FunctionData(input=[Obj(shape='triangle', color='red')], output=False, alpha=alpha)\n",
    "        ],\n",
    "        size=n\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f22ab-d5e5-4f81-b557-07d9ed74598a",
   "metadata": {},
   "source": [
    "Let's test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63f98087-6579-4ee6-8e39-e31c9557ceb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<<OBJECT: shape=square color=blue > -> False>,\n",
       "       <<OBJECT: shape=triangle color=red > -> False>,\n",
       "       <<OBJECT: shape=triangle color=red > -> False>,\n",
       "       <<OBJECT: shape=square color=blue > -> False>,\n",
       "       <<OBJECT: shape=square color=red > -> True>,\n",
       "       <<OBJECT: shape=triangle color=red > -> False>,\n",
       "       <<OBJECT: shape=triangle color=blue > -> False>,\n",
       "       <<OBJECT: shape=triangle color=blue > -> False>,\n",
       "       <<OBJECT: shape=triangle color=blue > -> False>,\n",
       "       <<OBJECT: shape=square color=blue > -> False>], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_data(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c89c2e-f4aa-4489-8904-ede25d3ab125",
   "metadata": {},
   "source": [
    "## Logical primitives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff84f86-d4f6-4670-9180-0564e49da452",
   "metadata": {},
   "source": [
    "These primitives are also defined in `LOTlib3.Primitives.Features` but I am reporting them here for completeness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20f42d79-5b83-48a5-b884-9b0a01005c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "@primitive\n",
    "def is_color_(x,y): \n",
    "    # simply check that the color attribute of\n",
    "    # the object is y\n",
    "    return (x.color == y)\n",
    "\n",
    "@primitive\n",
    "def is_shape_(x,y): \n",
    "    return (x.shape == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9b8942-b54b-470c-83b1-8a47c24ab8e0",
   "metadata": {},
   "source": [
    "As described in the introductory file for LOTlib3, the decorator `@primitive` allows us to use a function as a terminal in our grammar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ea088-8d4e-40c3-aab9-8bac94992df6",
   "metadata": {},
   "source": [
    "## Grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d0af8a-999f-4950-8e4d-11d5d0468ddd",
   "metadata": {},
   "source": [
    "The grammar that encodes 'Disjunctive Normal Form' can be found in `DefaultGrammars.py` (and imported with `from LOTlib3.DefaultGrammars import DNF`), but I am reporting it here for completeness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8bdb6f2-8d9a-4025-849e-a0608aa957b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRE-PREDICATE -> ['PREDICATE']\tw/ p=5.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEFAULT_FEATURE_WEIGHT = 5.\n",
    "\n",
    "grammar = Grammar()\n",
    "# NOTE: empty name argument is interpreted as a function with an 'empty' name\n",
    "# so it just works to add brackets around DISJ\n",
    "grammar.add_rule('START', '', ['DISJ'], 1.0)\n",
    "grammar.add_rule('START', '', ['PRE-PREDICATE'], DEFAULT_FEATURE_WEIGHT)\n",
    "grammar.add_rule('START', 'True', None, DEFAULT_FEATURE_WEIGHT)\n",
    "grammar.add_rule('START', 'False', None, DEFAULT_FEATURE_WEIGHT)\n",
    "\n",
    "grammar.add_rule('DISJ', '',     ['CONJ'], 1.0)\n",
    "grammar.add_rule('DISJ', '',     ['PRE-PREDICATE'], DEFAULT_FEATURE_WEIGHT)\n",
    "grammar.add_rule('DISJ', 'or_',  ['PRE-PREDICATE', 'DISJ'], 1.0)\n",
    "\n",
    "grammar.add_rule('CONJ', '',     ['PRE-PREDICATE'], DEFAULT_FEATURE_WEIGHT)\n",
    "grammar.add_rule('CONJ', 'and_', ['PRE-PREDICATE', 'CONJ'], 1.0)\n",
    "\n",
    "# A pre-predicate is how we treat negation\n",
    "grammar.add_rule('PRE-PREDICATE', 'not_', ['PREDICATE'], DEFAULT_FEATURE_WEIGHT)\n",
    "grammar.add_rule('PRE-PREDICATE', '',     ['PREDICATE'], DEFAULT_FEATURE_WEIGHT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1363eb-eb53-4f40-92da-d2349d59c456",
   "metadata": {},
   "source": [
    "We also need some predicates so that the grammar can interact with the observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "695c8e82-36fc-4426-8c1d-d638ebe9b5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SHAPE -> 'diamond'\tw/ p=1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Two predicates for checking x's color and shape\n",
    "# Note: per style, functions in the LOT end in _\n",
    "grammar.add_rule('PREDICATE', 'is_color_', ['x', 'COLOR'], 1.0)\n",
    "grammar.add_rule('PREDICATE', 'is_shape_', ['x', 'SHAPE'], 1.0)\n",
    "\n",
    "# Some colors/shapes each (for this simple demo)\n",
    "# These are written in quotes so they can be evaled\n",
    "grammar.add_rule('COLOR', q('red'), None, 1.0)\n",
    "grammar.add_rule('COLOR', q('blue'), None, 1.0)\n",
    "grammar.add_rule('COLOR', q('green'), None, 1.0)\n",
    "grammar.add_rule('COLOR', q('mauve'), None, 1.0)\n",
    "\n",
    "grammar.add_rule('SHAPE', q('square'), None, 1.0)\n",
    "grammar.add_rule('SHAPE', q('circle'), None, 1.0)\n",
    "grammar.add_rule('SHAPE', q('triangle'), None, 1.0)\n",
    "grammar.add_rule('SHAPE', q('diamond'), None, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefc9452-4091-4924-b061-60a42d80aad2",
   "metadata": {},
   "source": [
    "Look at some example of sentences generated by the grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09c54bb0-8ffa-4b1b-b942-188cc19fc493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not_(is_color_(x, 'red'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp = grammar.generate()\n",
    "hyp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df7064b-e2b1-4b22-9c8d-3d9f94542f90",
   "metadata": {},
   "source": [
    "## Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02251bb7-ad8e-42a0-a3c7-6014e60fa5a5",
   "metadata": {},
   "source": [
    "The hypothesis class in Piantadosi's code inherits from `RationalRulesPrior`, which implements a model from Goodman et al 2008, _A Rational Analysis of Rule-Based Concept Learning_. However, we found that that wasn't working right so I am just removing it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90ed2a54-383c-4ecb-a23e-73c7013dc040",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHypothesis(BinaryLikelihood, LOTHypothesis):\n",
    "    def __init__(self, **kwargs):\n",
    "        \n",
    "        # note that our grammar defined above is passed to \n",
    "        # MyHypothesis here\n",
    "        LOTHypothesis.__init__(self, grammar=grammar, **kwargs)\n",
    "        \n",
    "        # this is a parameter from the model in Goodman et al 2008\n",
    "        self.rrAlpha=2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd485d0-6b50-427d-83a3-01fd0e2202d0",
   "metadata": {},
   "source": [
    "With this, we can generate hypotheses from the grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "341f3e47-fe51-4902-8afb-677ad7e80190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lambda x: is_color_(x, 'green')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis = MyHypothesis()\n",
    "hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da635808-bead-416f-81c3-90a4809dd792",
   "metadata": {},
   "source": [
    "And use them, e.g., to calculate the likelihood of some data (here, the data sampled above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "527ba1ad-b145-46c1-9d35-74c7a767a148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0005001250416822429"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = make_data()\n",
    "hypothesis.compute_likelihood(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86519d4-213c-49ef-9f67-30d938f65877",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79536733-3601-4331-9a2d-aff1a37e63bb",
   "metadata": {},
   "source": [
    "Finally, we can do inference and find the 10 highest posterior hypotheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a183d24-e074-46a1-904d-7b982de49870",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = MyHypothesis()\n",
    "data = make_data()\n",
    "top = TopN(N=10)\n",
    "\n",
    "for i, h in enumerate(MetropolisHastingsSampler(h0, data, steps=10000)):\n",
    "    top << h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e84d03-9a21-4dfe-ac7c-67f248f19421",
   "metadata": {},
   "source": [
    "And print them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1322fb1-4247-4f4e-a903-ab18c9ee46d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11.761285918026795 -4.158883083359667 -7.602402834667128 \"lambda x: is_color_(x, 'red')\"\n",
      "-10.08780960949681 -10.085809109330082 -0.0020005001667289714 \"lambda x: and_(is_color_(x, 'red'), not_(is_shape_(x, 'triangle')))\"\n",
      "-10.08780960949681 -10.085809109330082 -0.0020005001667289714 \"lambda x: and_(is_shape_(x, 'square'), not_(is_color_(x, 'blue')))\"\n",
      "-10.08780960949681 -10.085809109330082 -0.0020005001667289714 \"lambda x: and_(not_(is_shape_(x, 'triangle')), is_color_(x, 'red'))\"\n",
      "-10.08780960949681 -10.085809109330082 -0.0020005001667289714 \"lambda x: and_(not_(is_color_(x, 'blue')), is_shape_(x, 'square'))\"\n",
      "-9.682344501388645 -9.680344001221917 -0.0020005001667289714 \"lambda x: and_(not_(is_shape_(x, 'triangle')), not_(is_color_(x, 'blue')))\"\n",
      "-9.682344501388645 -9.680344001221917 -0.0020005001667289714 \"lambda x: and_(not_(is_color_(x, 'blue')), not_(is_shape_(x, 'triangle')))\"\n",
      "-9.682344501388645 -9.680344001221917 -0.0020005001667289714 \"lambda x: and_(is_color_(x, 'red'), is_shape_(x, 'square'))\"\n",
      "-9.682344501388645 -9.680344001221917 -0.0020005001667289714 \"lambda x: and_(is_shape_(x, 'square'), is_color_(x, 'red'))\"\n",
      "-8.988697195787019 -1.386294361119889 -7.602402834667129 \"lambda x: False\"\n"
     ]
    }
   ],
   "source": [
    "for h in top:\n",
    "    print(h.posterior_score, h.prior, h.likelihood, qq(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "49a9ca0e-09bc-4490-a0a7-e3a7cdf56c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lambda x: False"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top.best()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80de4f3a-b6e9-436f-ac7e-1624017ade4d",
   "metadata": {},
   "source": [
    "This is a nice scaffolding, but much more can be done with this model. Here's some suggestions for the remainder of the class:\n",
    "\n",
    "> **__EXERCISES__** \n",
    "> - Add a feature to the grammar and objects, e.g. `is_size_`.\n",
    "> - Add what we saw in the Piantadosi et al paper, namely a system where whether an object belongs to the category can depend on which other objects are present in the situation.\n",
    ">    - In order to do this, you'll have to expand the expressive power of the grammar to include (higher order) functions.\n",
    ">    - NOTE: While this might seem a bit strange, we have similar phenomena in natural language. For instance, whether an object counts as 'large' or 'small' might depend on what other objects are relevant in the context. A 'large' mouse is smaller than a 'small' elephant.\n",
    "> - Create and plot a 'learning curve': \n",
    ">    - Produce some dataset with e.g., 200 examples from a certain true hypothesis.\n",
    ">    - Create cumulative sets of data: `[data[:10], data[:20], data[:30], ...]` (can also be written as `[data[:n] for n in range(10, 200, 10)]`). This simulates an experiment where the participant sees more and more of the data.\n",
    ">    - Train the model on each data, so that we have a series of posteriors trained on increasingly large portions of the data.\n",
    ">    - Plot the posterior probabilities of the overall most common hypotheses over time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LoT",
   "language": "python",
   "name": "lot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
